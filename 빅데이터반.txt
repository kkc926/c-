

어떤 데이터를 수집할지 판단하기

 ex)1인가구가 살기 좋은 동네?

1.안전
2.물가
3.집값
4.교통
등ㄷ
등
등.
.
.
.
.
 이런식으로 

그 후 데이터를 시각화 한다


Hadoop 
 - 서버
 - 오픈소스임
 - 첫 분산 처리 시스템 ( 파일의 사이즈에 관계없이 저장 가능함) -----> 많은 데이터를 처리할 수 있게 되었음.(이전에는 데이터 처리가 어려워 근 2년 혹은 홀수, 짝수년 데이터를 사용하였음)
 - 여러개의 컴퓨터의 각각 역할을 지정하고, 하나로 묶어 사용할 수 있게 해줌('클러스터'라고함)
 - 국내 업체에서도 많이 사용함
 - 데이터 손실을 방지하기위해 렉 별로 카피하여 저장함
 - 

map reduce
 - 데이터를 처리할 수 있는 기술 
 - 하드디스크에 읽고 쓰고를 반복하며 처리하기때문에 느림
spark
- 대용량 데이터를 처리할 수 있는 기술
- 진보한 map reduce // 읽기 쓰기를 하며 처리하지 않아 처리속도가 빠름 
- 쓸 수 있는 언어가 많음.
- 데이터 처리할 양이 많으면 사용하면 좋다.



1.전세자금 정책 제시
 - 년도별로 나누어/ 정부별 나누어 분석 후 결과 발표

2.서울시에 대중교통 사각지대 분석과 피해 분석
 - 지하철 많은 지역, 소외 지역을 시각화로 표시함.

3.새벽배송 
 - 효과

4.통신사 해지율 예측에 대한 마켓팅 방안 제시


5.국비지원학원 취업률 분석


6.날씨와 관련된 생활패턴 분석
 - 음식, 영화 ---42억개 데이터 분석함.
